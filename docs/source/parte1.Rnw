\documentclass[compress,serif]{beamer}  % t per mettere al top delle slide
%\documentclass[compress,serif,handout]{beamer}
%%% Dichiarazione dei pacchetti standard.
\usepackage[italian]{babel}
\usepackage{tikz}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{bm}
\usepackage{amsmath,amssymb}

%%%%%%%% colori
\definecolor{cambridgedarkblue}{RGB}{0,62,114}
\definecolor{cambridgedarkblue1}{RGB}{0,55,102}
\definecolor{cambridgedarkblue2}{RGB}{0,49,91}
\definecolor{cambridgedarkorange}{RGB}{200,78,0}
\definecolor{aqua}{cmyk}{11,17,0,0}
\definecolor{rossooutput}{rgb}{0.6,0,0}
\definecolor{grigiooutput}{RGB}{187,193,193}
\setbeamercolor{zen}{fg=orange!40!blue,bg=white!20!yellow}


%%% Personalizzazione del layout---articolata su cinque livelli.
\usetheme{Frankfurt}        % layout complessivo.
\usefonttheme{structurebold}
%%%% page number
\setbeamertemplate{footline}[frame number]
\setbeamerfont{footline}{size=\scriptsize, series=\bfseries}
\setbeamercolor{footline}{fg = black, bg = black}
\setbeamercolor{page number in head/foot}{fg = gray}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usecolortheme[named=cambridgedarkblue]{structure}
\setbeamercolor{palette primary}{bg=cambridgedarkblue,fg=white}
\setbeamercolor{palette secondary}{bg=cambridgedarkblue,fg=white}
\setbeamercolor{palette tertiary}{bg=white,fg=cambridgedarkblue}
\setbeamercolor{palette quaternary}{fg=white,bg=cambridgedarkblue}
\setbeamercolor{uppercolor}{fg=orange!80!white, bg=cambridgedarkblue2}
\setbeamercolor{lowercolor}{fg=white, bg=cambridgedarkblue1}
\setbeamercolor{upesempio}{fg=white, bg=orange}
\setbeamercolor{loesempio}{fg=black, bg=white!75!yellow}
\setbeamercolor{upnotabene}{fg=white, bg=rossooutput}
\setbeamercolor{lonotabene}{fg=red!70!black, bg=yellow!20!white}
\setbeamercolor{formula}{fg=black, bg=grigiooutput!60!white}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<include=FALSE>>=
library(knitr)
opts_chunk$set(fig.width=4, fig.height=3,echo=FALSE,dev="tikz",fig.align='center',results="hide",comment=NA,prompt=TRUE,cache=TRUE,external = TRUE)
opts_knit$set(out.format = "latex") #,width=30)
thm = knit_theme$get("autumn")  # approved by lptrainer
knit_theme$set(thm)

@

<<echo=FALSE,message=FALSE>>=
rm(list=ls())
main <- "~/didattica/Bertinoro/"
if (grepl("kolmogorov",Sys.info()["user"])) main <- gsub("~/","~/MEGAsync/",main)
if (grepl("cox",Sys.info()["user"])) main <- gsub("~/","~/MEGA/",main)
datadir <- paste(main,"data/",sep="")

nprob <- 1

# KUtils::pulizia(paste(main,"knitr",sep=""), tieni = c(".Rnw",".Rmd"))

@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Titolo e autore.
\title{\textbf{1. Inferenza statistica}}
\subtitle{\footnotesize{Tutto quello che sappiamo, non sappiamo, \\crediamo di sapere...}}
\author{\textbf{Massimiliano Pastore}\\
   Università di Padova}
\date{}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[plain]
  \titlepage
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[plain]
\frametitle{Una tazza di te}
\begin{beamerboxesrounded}[upper=zen, lower=lowercolor, shadow=true]
  {\textbf{Nan-in, un maestro giapponese dell'era Meiji (1868-1912), ricevette la visita di un professore universitario che era andato da lui per interrogarlo sullo Zen.} \pause

  \textbf{Nan-in serv\`{\i} il te. Colm\`{o} la tazza del suo ospite, e poi continu\`{o} a versare. Il professore guard\`{o} traboccare il te, poi non riusc\`{\i} pi\`{u} a contenersi: ``\`{E} ricolma. Non ce n'entra pi\`{u}!''.} \pause

  \textbf{``Come questa tazza'' disse Nan-in ``tu sei ricolmo delle tue opinioni e congetture. Come posso spiegarti lo Zen, se prima non vuoti la tua tazza?''.}}
\scriptsize{("101 Storie Zen" a cura di Nyogen Senzaki e Paul Reps, Adelphi Edizioni, Milano, 1973)}
\end{beamerboxesrounded}


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Contenuti}
  \tableofcontents
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%5
\section{Definizioni di base}
%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Il giardino dei sentieri biforcati}}

\begin{flushleft}
  \scalebox{1}{\includegraphics{img/garden.png}}
\end{flushleft}

\begin{itemize}
 \item Nel racconto di Jorge Louis Borges, \emph{Il giardino dei sentieri biforcati}, si fa riferimento ad un libro ed un labirinto in cui si cerca di descrivere tutti i possibili risultati di un evento, ognuno dei quali produce una ulteriore proliferazione di conseguenze possibili.
\end{itemize}


\vspace{1cm}
\noindent\rule{5cm}{0.4pt}

\tiny Thanks to Richard Mc Elreath.
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Popolazione e campione}
\begin{frame}{\textbf{Popolazione e campione}}

\begin{itemize}
  \item A \textbf{population} can be defined as including all people or items with the characteristic one wishes to understand. It can be a group of existing objects or a hypothetical and potentially infinite group of objects conceived as a generalization from experience (`Glossary of statistical terms: Population`. \texttt{Statistics.com}).
  \item A \textbf{sample} is a set of individuals or objects collected or selected from a statistical population by a defined procedure (Peck \& al. 2008).
\end{itemize}



\vspace{1cm}
\noindent\rule{5cm}{0.4pt}

\tiny Peck, R., Olsen, C., \& Devore, J. L. (2008). Introduction to statistics and data analysis (3rd ed.), Belmont, Cal.: Thomson Brooks/Cole.

\end{frame}



\begin{frame}{\textbf{Popolazione e campione}}

\begin{columns}
\begin{column}{.6\textwidth}

\begin{tikzpicture}[>=latex, scale = 1]

%\draw[style=help lines] (-7,0) grid (3,2); %,color=white
\node (omega) at (-5,-1) {};
\node (sample1) at (-2.6,-3.4) {};
\node (sample2) at (-1.6,-2) {};
\node (sample3) at (-2.4,-.75) {};
\node (sample4) at (-4.6,-3.9) {};

%% connessioni
\draw[thick, ->, line width=2pt] (omega) -- (sample1);
\draw[thick, ->, line width=2pt] (omega) -- (sample2);
\draw[thick, ->, line width=2pt] (omega) -- (sample3);
\draw[thick, ->, line width=2pt] (omega) -- (sample4);

%% POPOLAZIONE
\shadedraw[shading=ball,ball color=blue,white,name=omega] (-5,-1) circle (1.8);
   \filldraw  (-5,-1) node[white, scale=2.5] {\Huge{\textbf{$\Omega$}}};

%% CAMPIONI
\shadedraw[shading=ball,ball color=blue!40,white,name=sample1] (-2.5,-3.5) circle (.3);
   \filldraw  (-2,-3.2) node[scale=.5] {\Huge{\textbf{$X_1$}}};

\shadedraw[shading=ball,ball color=blue!70,white] (-1,-2) circle (.7);
\filldraw  (-.2,-1.5) node[scale=.5] {\Huge{\textbf{$X_2$}}};

\shadedraw[shading=ball,ball color=blue!20!gray,white] (-2.1,-.6) circle (.4);
\filldraw  (-1.55,-.25) node[scale=.5] {\Huge{\textbf{$X_3$}}};

\shadedraw[shading=ball,ball color=red!70,white] (-4.6,-4) circle (.2);
\filldraw  (-4.2,-3.8) node[scale=.5] {\Huge{\textbf{$X_4$}}};

\end{tikzpicture}


%\input{img/campionamento}
\end{column}
\begin{column}{.35\textwidth} \pause
\begin{beamerboxesrounded}[shadow=true,upper=upesempio,lower=loesempio]{}
 \textbf{I campioni che si estraggono da una popolazione possono essere più o meno simili alla popolazione stessa.}
 \end{beamerboxesrounded}
\end{column}
\end{columns}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\begin{beamerboxesrounded}[upper=title, lower=loesempio, shadow=true]
  {\textbf{In pratica}}
    \begin{itemize}
       \item \textbf{Noi vorremmo conoscere la popolazione, ma possiamo solo osservare uno o (nei casi più fortunati) più campioni.}
       \item \textbf{Pertanto, conoscere le proprietà delle statistiche ottenute sui campioni ci serve per avere informazioni su come potrebbe essere la popolazione.}
    \end{itemize}
\end{beamerboxesrounded}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Parametri e statistiche} % toglinelprint
\begin{frame}
    \frametitle{\textbf{Parametri e statistiche}}

\begin{itemize}
  \item Un \textbf{parametro} \`e una caratteristica della popolazione espressa con un certo valore (solitamente numerico).
  \item Una \textbf{statistica} \`e un valore che, per mezzo di una funzione, viene associato ad una caratteristica di un qualsiasi campione di ampiezza $n$, appartenente ad una data popolazione.
  \item Generalmente i parametri sono valori incogniti, mentre le statistiche valori rilevati empiricamente che vengono utilizzati come stimatori dei parametri incogniti.
\end{itemize}
\pause[]
\vspace{.3cm}
\begin{beamerboxesrounded}[upper=upnotabene, lower=lonotabene, shadow=true]
    {\center{\textbf{NOTA BENE}}}
    Le statistiche si indicano con lettere latine (es. $\overline{x}$, $s^2$) mentre i parametri si indicano con lettere greche (es. $\mu$, $\sigma^2$).
\end{beamerboxesrounded}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Inferenza}
\begin{frame}
\frametitle{Inferenza}

\vspace{-.3cm}
\begin{itemize}
    \item L'\textbf{inferenza} \`{e} un processo logico per il quale, data una o pi\`{u} premesse, \`{e} possibile trarre una conclusione.
    \item Ne possiamo distinguere due tipi:
\end{itemize}

\pause[]
\begin{columns}
\begin{column}{0.5\textwidth}
\vspace{-1.1cm}

\begin{beamerboxesrounded}[upper=uppercolor, lower=lowercolor, shadow=true]
    {\textbf{Inferenza deduttiva}}
    \textbf{Quando parte da premesse certe ed arriva a conclusioni certe.}
\end{beamerboxesrounded}

\vspace{.1cm}
\begin{beamerboxesrounded}[upper=upesempio, lower=loesempio, shadow=true]
    {\textbf{Esempio}}
    \begin{itemize}
        \item Ogni triangolo rettangolo ha un angolo di $90^\circ$.
        \item Il triangolo $T$ \`{e} rettangolo.
        \pause[]
        \item Il triangolo $T$ ha un angolo di $90^\circ$.
    \end{itemize}
\end{beamerboxesrounded}

\end{column}
\pause[]
\vspace{-.1cm}
\begin{column}{0.5\textwidth}
\begin{beamerboxesrounded}[upper=uppercolor, lower=lowercolor, shadow=true]
    {\textbf{Inferenza induttiva}}
    \textbf{Quando parte da premesse certe ed arriva a conclusioni probabili.}
\end{beamerboxesrounded}

\vspace{.1cm}
\begin{beamerboxesrounded}[upper=upesempio, lower=loesempio, shadow=true]
    {\textbf{Esempio}}
       \begin{itemize}
        \item Ho visto un corvo ed era nero.
        \item Ho visto un secondo corvo ed era nero.
        \item ....
        \pause[]
        \item Probabilmente tutti i corvi sono neri.
    \end{itemize}
\end{beamerboxesrounded}
\end{column}
\end{columns}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Elezioni presidenziali USA 1936}} %toglinelprint


\begin{columns}
\begin{column}{.5\textwidth}

\begin{itemize} \pause[2]
 \item La rivista \emph{Literary Digest} condusse un sondaggio elettorale basato su 2.3 milioni di rispondenti sulla base del quale veniva dato per sicuro vincente Alf Landon. \pause[3]
 \item In realtà poi stravinse Roosvelt con oltre il 60\% dei voti.
\end{itemize}

\end{column}

\begin{column}{.5\textwidth} \pause[1]
\scalebox{.15}{\includegraphics{img/presidenti.png}}
\end{column}

\end{columns}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Elezioni presidenziali USA 1936}} %toglinelprint

\begin{itemize}
 \item La rivista aveva contattato 10 milioni di cittadini dalle liste del registro automobilistico e dall'elenco telefonico. \pause

 \item Contemporaneamente, lo statistico George Gallup aveva predetto la vittoria di Roosevelt utilizzando un campione molto più piccolo (50000 persone). Non solo, ma con un esiguo sottoinsieme di 3000 persone incluse nella lista del \emph{Digest} Gallup replicò i risultati ottenuti dalla rivista.

 \item Come mai?
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{}
\begin{frame}
\frametitle{\textbf{Dal campione alla popolazione}}

\begin{columns}
\begin{column}{.6\textwidth}
\only<1>{

\begin{tikzpicture}[>=latex, scale = 1]

%\draw[style=help lines] (-7,0) grid (3,2); %,color=white
\node (omega) at (-5,-1) {};
\node (sample1) at (-2.6,-3.4) {};
\node (sample2) at (-1.6,-2) {};
\node (sample3) at (-2.4,-.75) {};
\node (sample4) at (-4.6,-3.9) {};

%% connessioni
\draw[thick, ->, line width=2pt] (omega) -- (sample1);
\draw[thick, ->, line width=2pt] (omega) -- (sample2);
\draw[thick, ->, line width=2pt] (omega) -- (sample3);
\draw[thick, ->, line width=2pt] (omega) -- (sample4);

%% POPOLAZIONE
\shadedraw[shading=ball,ball color=blue,white,name=omega] (-5,-1) circle (1.8);
   \filldraw  (-5,-1) node[white, scale=2.5] {\Huge{\textbf{$\Omega$}}};

%% CAMPIONI
\shadedraw[shading=ball,ball color=blue!40,white,name=sample1] (-2.5,-3.5) circle (.3);
   \filldraw  (-2,-3.2) node[scale=.5] {\Huge{\textbf{$X_1$}}};

\shadedraw[shading=ball,ball color=blue!70,white] (-1,-2) circle (.7);
\filldraw  (-.2,-1.5) node[scale=.5] {\Huge{\textbf{$X_2$}}};

\shadedraw[shading=ball,ball color=blue!20!gray,white] (-2.1,-.6) circle (.4);
\filldraw  (-1.55,-.25) node[scale=.5] {\Huge{\textbf{$X_3$}}};

\shadedraw[shading=ball,ball color=red!70,white] (-4.6,-4) circle (.2);
\filldraw  (-4.2,-3.8) node[scale=.5] {\Huge{\textbf{$X_4$}}};

\end{tikzpicture}

%\input{img/campionamento}
}
\only<2>{
\begin{tikzpicture}[>=latex, scale = 1]

%\draw[style=help lines] (-7,0) grid (3,2); %,color=white
\node (omega) at (-3.8,-2.1) {};
\node (sample1) at (-2.6,-3.4) {};
\node (sample2) at (-1.6,-2) {};
\node (sample3) at (-2.4,-.75) {};
\node (sample4) at (-4.6,-3.9) {};

%% POPOLAZIONE
\shadedraw[shading=ball,ball color=white,white,name=omega] (-5,-1) circle (1.8);
   \filldraw  (-5,-1) node[black, scale=2] {\Huge{\textbf{???}}};

%% connessioni
\draw[thick, <-, line width=2pt] (omega) -- (sample1);

%% CAMPIONI
\shadedraw[shading=ball,ball color=blue!40,white,name=sample1] (-2.5,-3.5) circle (.3);
   \filldraw  (-2,-3.2) node[scale=.5] {\Huge{\textbf{$X_1$}}};


\end{tikzpicture}

%\input{img/inferenza}
}

\end{column}
\begin{column}{.35\textwidth}

\only<1>{
\begin{beamerboxesrounded}[shadow=true,upper=upesempio,lower=loesempio]{}
 \textbf{I campioni che si estraggono da una popolazione possono essere più o meno simili alla popolazione stessa.}
 \end{beamerboxesrounded}
}

\only<2>{
\begin{beamerboxesrounded}[shadow=true,upper=upesempio,lower=loesempio]{}
 \textbf{Quindi come facciamo ad avere informazioni sulla popolazione a partire dai dati del campione?}
 \end{beamerboxesrounded}

}
\end{column}
\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{L'idea del campionamento}}

\begin{itemize}
 \item Se non sappiamo come è fatta una popolazione, campioniamo ripetutamente da essa.
 \item Questo approccio diventa cruciale nell'approccio bayesiano; se non conosciamo la forma analitica della \emph{posterior}, la approssimiamo per campionamento.
\end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Example}}

<<>>=
set.seed(1)
DF <- 3
Omega <- rchisq(1e7, DF )
@

Supponiamo di voler approssimare una distribuzione ignota per campionamento.

\only<1>{
<<fig.height=3,dev='pdf'>>=
library(ggplot2)
set.seed(1)
y <- sample( Omega, 1 )
myData <- data.frame(y=y)
ggplot( myData ) + theme_minimal()
@

}

\only<2>{
<<echo=TRUE>>=
y <- sample( Omega, 1 )
@

<<fig.height=2,dev='pdf'>>=
myData <- data.frame(y=y)
ggplot( myData ) + theme_minimal()
@


}


\only<3>{

<<echo=TRUE>>=
y <- sample( Omega, 1 )
@

<<fig.height=2>>=
myData <- data.frame(y=y)
ggplot( myData, aes(x=y,y=0) ) + theme_bw() + geom_point(color="red", size = 3) + scale_y_continuous(limits = c(0,1),breaks = NULL) + xlab("") + ylab("")
@

}

\only<4>{
<<echo=TRUE>>=
y <- sample( Omega, 10 )
@

<<fig.height=2,dev='pdf'>>=
ggplot(myData) + theme_minimal()
@

}

\only<5>{

<<echo=TRUE>>=
y <- sample( Omega, 10 )
@

<<fig.height=2,message=FALSE>>=
myData <- data.frame(y=y)
ggplot( myData, aes(x=y) ) + theme_bw() + geom_density() +
  geom_point(color="red", fill = "red",aes(x=y,y=0)) + scale_y_continuous( breaks = NULL ) + xlab("") + ylab("")
@

}


\only<6>{
<<echo=TRUE>>=
y <- sample( Omega, 100 )
@

<<fig.height=2,dev='pdf'>>=
ggplot(myData) + theme_minimal()
@

}

\only<7>{

<<echo=TRUE>>=
y <- sample( Omega, 100 )
@

<<fig.height=2,message=FALSE>>=
myData <- data.frame(y=y)
ggplot( myData, aes(x=y) ) + theme_bw() + geom_density() +
  geom_rug(color="red") + scale_y_continuous( breaks = NULL ) + xlab("") + ylab("")
@

}

\only<8>{
<<echo=TRUE>>=
y <- sample( Omega, 1000 )
@

<<fig.height=2,dev='pdf'>>=
ggplot(myData) + theme_minimal()
@

}

\only<9>{

<<echo=TRUE>>=
y <- sample( Omega, 1000 )
@

<<fig.height=2,message=FALSE>>=
myData <- data.frame(y=y)
ggplot( myData, aes(x=y) ) + theme_bw() + geom_density() +
  geom_rug(color="red") + scale_y_continuous( breaks = NULL ) + xlab("") + ylab("")
@


}


\only<10> {
<<echo=TRUE>>=
y <- sample( Omega, 10000 )
@

<<fig.height=2,dev='pdf'>>=
ggplot(myData) + theme_minimal()
@

}

\only<11>{
<<echo=TRUE>>=
y <- sample( Omega, 10000 )
@

<<fig.height=2,message=FALSE>>=
myData <- data.frame(y=y)
x <- quantile(Omega,probs = .997)
y <- dchisq(2,DF)

(GG <- ggplot( myData, aes(x=y) ) + theme_bw() + geom_density() +
    geom_rug( color = "red" )+ scale_y_continuous( breaks = NULL ) + xlab("") + ylab(""))

#  geom_point(color="red", fill = "red",aes(x=y,y=0))
@

}

\only<12>{
<<echo=TRUE>>=
y <- sample( Omega, 10000 )
@

<<fig.height=2,message=FALSE>>=
xx <- quantile(Omega,probs = .997)
yy <- dchisq(2,DF)

GG <- ggplot( myData, aes(x=y) ) + theme_bw() + geom_density() +
    geom_rug( color = "red" )+ scale_y_continuous( breaks = NULL ) + xlab("") + ylab("")

GG + annotate("text", x=xx, y=yy, label ="Di quale distribuzione di tratta?")

@

}

\only<13>{
<<echo=TRUE>>=
y <- sample( Omega, 10000 )
@

<<fig.height=2,message=FALSE>>=
GG + stat_function( fun = dchisq, args = list(df=DF), color = "blue", lwd = 1.5 ) #+ annotate("text", x=x, y=y, label =" ")
@

}


\only<14>{
<<echo=TRUE>>=
y <- sample( Omega, 10000 )
@

<<fig.height=2,message=FALSE>>=
GG + stat_function( fun = dchisq, args = list(df=DF), color = "blue", lwd = 1.5 ) + annotate("text", x=xx, y=yy, label =paste0("$\\chi^2(",DF,")$"))
@

}
\end{frame}

\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{Inferenza statistica}}

\begin{itemize}
  \item \emph{Statistical inference can be formulated as a set of operations on data that yield estimates and uncertainty statements about predictions and parameters of some underlying process or population} (Gelman, Hill \& Vehtari, 2020).
  \item I due approcci principali all'inferenza sono quello frequentista e quello bayesiano.
\end{itemize}



\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[NHST]{Inferenza frequentista}
\begin{frame}[plain]

\begin{beamerboxesrounded}[upper=title, lower=structure, shadow=true]
    {\center{\Large{\textbf{Inferenza in senso frequentista}}}}
\begin{itemize}
    \item L'approccio NHST
    \item Il teorema di Bayes
    \item I limiti dell'approccio NHST
\end{itemize}
\end{beamerboxesrounded}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{Problema \Sexpr{nprob}}} % toglinelprint
<<>>=
nprob <- nprob+1
@
\begin{beamercolorbox}[rounded=true, shadow=true]{loesempio}
\textbf{Vogliamo stimare la proporzione (o la percentuale) di studenti iscritti ai corsi della Scuola di Psicologia a cui piace la Statistica.
}
\end{beamercolorbox}

\vspace{.3cm}
<<>>=
load(paste0(datadir,"questionario2024.rda"))
Questionario <- Questionario2024
n <- nrow(Questionario)
n_piace <- sum(Questionario$Q06_quantopiace>6,na.rm = TRUE)
obsp <- n_piace/n
@
Usiamo i dati di un questionario rilevato all'inizio di un corso di Analisi dei Dati:

\begin{itemize}
  \item Rispondenti: $n=\Sexpr{n}$
  \item Piace ($>6$): $n_{\text{piace}}=\Sexpr{n_piace}$
  \item Proporzione campionaria: $\frac{n_{\text{piace}}}{n} = \frac{\Sexpr{n_piace}}{\Sexpr{n}} = \Sexpr{round(n_piace/n,2)}$
  \item Percentuale campionaria: $\frac{n_{\text{piace}}}{n}  \times 100 = \frac{\Sexpr{n_piace}}{\Sexpr{n}} \times 100 = \Sexpr{round(n_piace/n*100)}$\%
\end{itemize}

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] % toglinelprint

<<results='markup'>>=
p_piace <- 0:100 / 100
cat("> p_piace <- 0:100 / 100","\n")
@
\pause \vspace{-.5cm}
<<results='markup'>>=
L <- dbinom( n_piace, n, prob = p_piace)
cat(paste0("> L <- dbinom( ",n_piace,", ",n,", prob = p_piace )"),"\n")
@
\pause \vspace{-.5cm}
<<sanitize=TRUE,fig.keep='none',echo=TRUE>>=
plot( p_piace, L, type = 'h' )
points( p_piace, L, pch = 19 )
@
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Verosimiglianza}} % toglinelprint

\only<1>{
<<warning=FALSE>>=
library(ggplot2)
P <- data.frame(p_piace,L)
(PLOT <- ggplot(P,aes(p_piace,L))+theme_bw()+geom_segment(aes(xend=p_piace,yend=0),color=gray(.5))+geom_point(size=.5) + xlab("Proporzione di studenti a cui piace la statistica") + ylab(paste("Likelihood")))
@
}
\only<2>{
<<warning=FALSE>>=

POINTCEX <- 2
Lobsp <- dbinom(n_piace,n,prob = obsp)
PLOT + annotate("segment",x=obsp,xend=obsp,y=0,yend=Lobsp,col="red",lwd=.8,lty=2) +
annotate("point",x=obsp,y=0,col="red",size=POINTCEX) + annotate("point",obsp,Lobsp,col="orange",size=POINTCEX)

@

}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}\frametitle{\textbf{Test di ipotesi}}

\pause
\begin{beamerboxesrounded}[upper=uppercolor, lower=loesempio, shadow=true]
    {\textbf{Ipotesi $H_0$}} \pause
La proporzione di studenti a cui piace la statistica è uguale a quella degli studenti a cui non piace.

Formalmente $$H_0: \pi_{\text{piace}}=0.5$$
\end{beamerboxesrounded}

\vspace{.3cm} \pause
\begin{beamerboxesrounded}[upper=uppercolor, lower=loesempio, shadow=true]
    {\textbf{Ipotesi $H_1$}} \pause
La proporzione di studenti a cui piace la statistica è diversa da quella degli studenti a cui non piace.  \pause

Pu\`o essere bidirezionale \vspace{-.3cm} $$H_1: \pi_{\text{piace}} \neq 0.5$$ o monodirezionale \vspace{-.3cm} $$H_1: \pi_{\text{piace}} < 0.5 \makebox[.5cm]{} H_1: \pi_{\text{piace}} > 0.5$$
\end{beamerboxesrounded}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] % toglinelprint

<<results='markup'>>=
S <- 0:n # spazio campionario
cat(paste0("> S <- 0:",n,"  # spazio campionario"),"\n")
@
\pause \vspace{-.5cm}
<<results='markup'>>=
P <- dbinom(S,n,prob=.5)
cat(paste0("> P <- dbinom( S, ",n,", prob = .5 )"),"\n")
@
\pause \vspace{-.5cm}
<<echo=TRUE,fig.keep="none">>=
plot( S, P, type = 'h' )
points( S, P, pch = 19 )
@

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Distribuzione campionaria sotto $H_0$}} % toglinelprint

\only<1>{
<<>>=
Z <- data.frame(S,P)
(PLOT <- ggplot(Z,aes(S,P))+theme_bw()+geom_bar(stat="identity",width = .1) +geom_point(size=.5) + xlab(paste0("Numero di sudenti a cui piace in un campione di ",n," individui")) + ylab("$f(p|H_0)$") + theme(axis.title.x = element_text(size = 8)) )
@
}
\only<2>{
<<>>=
Lobsp <- with(Z, P[S==n_piace])
(PLOT <- PLOT + annotate("segment",x=n_piace,xend=n_piace,y=0,yend=Lobsp,col="red",lwd=.8,lty=2) + annotate("point",n_piace,0,col="red",size=POINTCEX))
@
}
\only<3>{
<<H0>>=
xpos <- ifelse(n_piace<10,n_piace*1.1,12)

PLOT + geom_ribbon(aes(ymin=0,ymax=P),data=subset(Z,S<=n_piace),fill="orange",alpha=.6) + annotate("text",xpos/2,subset(Z, S==n_piace)$P+.01,label=paste0("$Prob\\left(P \\leq \\frac{",n_piace,"}{",n,"}|H_0\\right)$"),size=2.8)+geom_point(aes(S,P),col="orange",size=POINTCEX, data=subset(Z,S<=n_piace))
@

}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{} % toglinelprint
\textbf{$Prob\left(P \leq \frac{\Sexpr{n_piace}}{\Sexpr{n}}| H_0 \right) =  $}
\pause
<<results='markup'>>=
cat(paste0("> pbinom( ",n_piace,", ",n,", prob = .5 )"),"\n")
@
\pause \vspace{-.6cm}
<<results='markup'>>=
pbinom(n_piace,n,prob=.5)
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Test Binomiale}} % toglinelprint

\small
<<results='markup'>>=
cat(paste0("> binom.test( ",n_piace,", ",n,", alternative = 'less' )"),"\n")
@
\pause \vspace{-.5cm}
<<results='markup'>>=
options(width = 60)
L <- capture.output(binom.test(n_piace,n,alternative = "less"))
L <- gsub("\t","     ",L)
L <- gsub("n_piace and n", paste0(c(n_piace,n),collapse=" and "),L)
L <- gsub("p-value", "                                    p-value",L)
riga <- grep("alternative",L)
L <- L[c(1:riga,riga:length(L))]
L[riga] <- substr(L[riga],1,23)
L[riga+1] <- gsub("alternative hypothesis:","    ",L[riga+1])
for (j in 1:length(L)) cat(L[j],"\n")
@
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%
\subsection{L'approccio NHST}
\begin{frame}{\textbf{L'approccio NHST}}
\footnotesize \pause
  \begin{center}
  %\input{img/nhstscheme}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{tikzpicture}[>=latex, scale = 1.1]

\draw [->, line width=1pt,aqua] (-2.06,3.8) -- (-1,3.3);
\draw [->, line width=1pt,grigiooutput] (-.7,2.4) -- (-2,1.5);
\draw [->, line width=1pt,aqua] (0,2.2) -- (0,1.4);
\draw [->, line width=1pt,grigiooutput] (-3,.5) -- (-2.7,-.1);
\draw [->, line width=1pt,aqua] (-.9,-.1) -- (-1.6,-.5);

\filldraw[fill=aqua,line width=1pt,aqua]
	   (-3,4.2) ellipse (1.1 and 0.8)
	   (0,3) ellipse (1.1 and 0.8)
     (0,.5) ellipse (1.2 and 0.9)
     (-2.5,-.8) ellipse (1 and 0.7);

\filldraw[fill=grigiooutput,line width=1pt,grigiooutput]
	   (-3.2,1.4) ellipse (1.2 and 0.9);

 \filldraw
	  (-3,4.4) node[white] {\textbf{Definizione di}}
    (-3,4) node[white] {\textbf{$\bm{H}_0$ e $\bm{H}_1$}}
    (0,3.2) node[white] {\textbf{Calcolo di}}
    (0,2.8) node[white] {\textbf{$\bm{T}_0=\bm{T}(\bm{X})$}}
    (-1.68,2.6) node[scale=.8] {\textbf{senza}}
    (-1.68,2.35) node[scale=.8] {\textbf{software}}
    (-3.2,1.8) node[white] {\textbf{Confronto tra}}
    (-3.2,1.4) node[white] {\textbf{$\bm{T}_0$ e valore}}
    (-3.2,1.0) node[white] {\textbf{critico $\bm{T}_c$}}
    (0,.9) node[white] {\textbf{Confronto tra}}
    (0,.5) node[white] {\textbf{$\bm{p}$-value e valore}}
    (0,.12) node[white] {\textbf{critico $\bm{\alpha}$}}
    (-2.5,-.8) node[white] {\textbf{Decisione}}
    (.8,2) node[scale=.8] {\textbf{con}}
    (.8,1.75) node[scale=.8] {\textbf{software}};

\end{tikzpicture}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%55
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{L'approccio NHST}}

\begin{itemize}
    \item Lo schema appena descritto entra in un approccio classico che \`e pi\`u corretto chiamare \emph{Null Hypothesis Significance Testing} (\textbf{NHST}) piuttosto che \emph{Verifica di ipotesi}.
    \item Possiamo riassumere tale approccio nel seguente modo:
    \begin{enumerate}
      \item Dato un campione di osservazioni $X$, si calcola una determinata statistica test $T_0=T(X)$. \pause[]
      \item Conoscendo $f(T|H_0)$, ossia la distribuzione campionaria di $T$ sotto l'ipotesi $H_0$ determiniamo $P(T\geq T_0|H_0)$ cio\`e la probabilit\`a di ottenere un risultato uguale o pi\`u estremo rispetto a quello rilevato empiricamente $T_0$. \pause[]
      \item Se tale probabilit\`a (che chiameremo $p$-\emph{value}) risulta essere inferiore ad una soglia prefissata di $\alpha=0.05$ concluderemo rigettando l'ipotesi $H_0$ altrimenti no.
    \end{enumerate}
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{L'approccio NHST}}

\begin{itemize}
  \item Secondo tale approccio i risultati che otteniamo rispondono alla domanda:
\end{itemize}

\begin{beamercolorbox}[rounded=true, shadow=true]{loesempio}
\textbf{Assumendo che $H_{0}$ sia vera, qual \`{e} la probabilit\`{a} di osservare (a caso) valori uguali o pi\`{u} estremi rispetto a quelli empiricamente rilevati?}
\end{beamercolorbox}      \pause[]
\begin{itemize}
  \item In realt\`{a} noi vorremmo rispondere alla domanda:
\end{itemize}
\begin{beamercolorbox}[rounded=true, shadow=true]{loesempio}
\textbf{Dati questi valori osservati, qual \`{e} la probabilit\`{a} che la mia ipotesi ($H_1$) sia vera?}
\end{beamercolorbox}      \pause[]
\begin{itemize}
  \item \textcolor[rgb]{0.98,0.00,0.00}{\textbf{Non si tratta esattamente della stessa cosa}!!}
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{$\bm{P(R|H_0)\neq P(H_0|R)}$}

\vspace{-.5cm}
\begin{itemize}
  \item I test statistici che si rifanno all'approccio NHST stimano
\end{itemize}

\begin{beamerboxesrounded}[upper=uppercolor, lower=loesempio, shadow=true]
    {\center{$\bm{P(R|H_0)}$}}
    \pause[] Probabilit\`{a} di ottenere il risultato $R$ condizionata al fatto che sia vera $H_0$ (verosimiglianza).
\end{beamerboxesrounded}

\pause[]

\begin{itemize}
  \item In realt\`{a} noi saremmo interessati a stimare
\end{itemize}

\begin{beamerboxesrounded}[upper=uppercolor, lower=loesempio, shadow=true]
    {\center{$\bm{P(H_0|R)}$}}
    \pause[] Probabilit\`{a} che sia vera l'ipotesi $H_0$ condizionata all'aver osservato il risultato $R$ (probabilit\`{a} a posteriori).
\end{beamerboxesrounded}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Teorema di Bayes}
\begin{frame}
\frametitle{\textbf{Teorema di Bayes}}

\vspace{-.8cm} %\small
\begin{columns}
\begin{column}{.45\textwidth}
\vspace{1.5cm}

Il legame tra le due probabilit\`{a} \`{e} definito dal \textbf{Teorema di Bayes}.
\end{column}
\begin{column}{.5\textwidth}
\scalebox{.28}{\includegraphics{img/sheldonbayes.png}}
\end{column}
\end{columns}

\vspace{.2cm}
\begin{beamerboxesrounded}[upper=formule, lower=formula, shadow=true]
    { }
    $$P(H_{0}|R) =
    \frac{P(H_{0})P(R|H_{0})}{P(H_{0})P(R|H_{0})+P(H_{1})P(R|H_{1})}$$
\end{beamerboxesrounded}

    \noindent in cui:

    \begin{itemize}
        \item $P(H_{0})$ \`{e} la probabilit\`{a} a priori di $H_{0}$
        \item $P(R|H_{0})$ \`{e} la probabilit\`{a} del risultato $R$ condizionato ad $H_{0}$
        \item $P(H_{0}|R)$  \`{e} la probabilit\`{a} a posteriori
    \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{Esempio (Cohen, 1994)}} % toglinelprint

\vspace{-.5cm}
L'incidenza della schizofrenia negli adulti \`e circa del $2\%$. Supponiamo di avere un test per la diagnosi di tale patologia con il $95\%$ di accuratezza nell' individuazione dei soggetti realmente schizofrenici, e circa il $97\%$ nell' individuazione dei soggetti sani.
\pause[]

Possiamo allora indicare con:
\begin{itemize}
  \item $H_0$: il soggetto \`{e} normale
  \item $H_1$: il soggetto \`{e} schizofrenico
  \item $R$ = risultato del test positivo per la schizofrenia
\end{itemize}

Pertanto avremo le seguenti probabilit\`{a}:
\vspace{-.2cm}
\begin{center}
\begin{tabular}{|c|c|}
  \hline
  $P(H_0)=0.98$ & \pause[] $P(H_1)=0.02$ \\
  \hline
\pause[] $P(R|H_0)=0.03$ & \pause[] $P(R|H_1)=0.95$ \\
  \hline
\end{tabular}
\end{center}
\vspace{-.2cm}
Si noti che $P(R|H_0)$ \`{e} minore del $5\%$.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{Esempio (Cohen, 1994)}} % toglinelprint

Calcoliamo la probabilit\`{a} a posteriori utilizzando il teorema di Bayes:

    $$P(H_{0}|R) =
    \frac{0.98\times0.03}{0.98\times0.03+0.02\times0.95} \simeq 0.61$$

\pause[]
\vspace{.3cm}
Nonostante la verosimiglianza $P(R|H_0)=0.03$ sia minore di $0.05$ abbiamo una probabilit\`{a} a posteriori molto pi\`{u} alta, $P(H_{0}|R)=0.61$.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame} % toglinelprint

<<message=FALSE>>=
library(riskyr)
prev <- .02
sensitivity <- accuracy <- .95
specificity <- .97
POP <- 1e4
Nsani <- POP*(1-prev)
Nskiz <- POP*prev
#comp_PPV(prev = pskizo, sens = .95, spec = .97)
@
\vspace{-1.2cm}
<<sanitize=TRUE,fig.width=4.5>>=
#,fig.width=10,fig.height=7
plot_prism(prev=prev, sens = sensitivity, spec = specificity, by = "cd", N= POP, cex_lbl = .9, cex_p_lbl = .9, main = NA, sub = " " ) #, main = " ", sub = " ", mar_notes = FALSE )
@

\small \vspace{-1cm}
\begin{center}
Se consideriamo tutta la popolazione, qual è la proporzione di individui positivi al test che non sono realmente malati?  \end{center} \pause
$$ \frac{\Sexpr{round(Nsani*(1-specificity))}}{(\Sexpr{Nskiz*accuracy}+\Sexpr{round(Nsani*(1-specificity))})}=\frac{\Sexpr{round(Nsani*(1-specificity))}}{\Sexpr{round((Nskiz*accuracy)+(Nsani*(1-specificity)))}} \approx \Sexpr{round(Nsani*(1-specificity)/((Nskiz*accuracy)+(Nsani*(1-specificity))),2)} = P(H_0|R)$$

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Relazione tra $p$-value e $p(H_0|x)$ \small{(Pastore \& Altoé, 2013)}\footnote{\tiny{Pastore, M., Altoé, G. (2013). Bayes Factor e $p$-value: così vicini, così lontani. \textit{Giornale italiano di psicologia}, 40, 175-193.}}}

\centering
<<echo=FALSE,message=FALSE,fig.height=2.85>>=
load(paste(main,"data/Pastore_Altoe_2013.rda",sep=""))

set.seed(20181008)
X1 <- X[sample(1:nrow(X),2000),]

TEXTCEX <- 7; LWD <- .4
ggplot(X1,aes(p,post.c))+theme_bw()+facet_grid(d~n)+geom_smooth(lwd=LWD)+geom_point(size=.5)+xlab("$p$-value")+ylab("$p(H_0|x)$")+theme(text = element_text(size=TEXTCEX))+scale_x_continuous(breaks = seq(0,.9,by=.25))
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Relazione tra $p$-value e $p(H_0|x)$ con $H_0$ vera!!}

\centering
<<echo=FALSE>>=
X1 <- subset(X,(X$d==0)&(X$p<=.1))
X1$n <- factor(X1$n)
ggplot(X1,aes(p,post.c,colour=n))+theme_bw()+geom_point(size=1)+xlab("$p$-value")+ylab("$p(H_0|x)$")+geom_vline(xintercept = .05,linetype = "longdash")

@
\end{frame}

%%%%%%%%
\subsection{The null ritual}
\begin{frame}{The null ritual (\small{Gigerenzer Krauss \& Vitouch, 2004})}

\begin{itemize} \pause
  \item The null ritual is an invention of statistical textbook writers in the social sciences.
  \item The null ritual does not exist in statistic proper. What does exist are conflicting theories of inference, most relevantly those of Fisher and Neyman-Pearson.
  \item One rarely finds a hint at this controversy in statistics textbooks written by social scientists. As a result, the null ritual is confused with Fisher's theory of null hypothesis testing.
\end{itemize}

\noindent\rule{5cm}{0.4pt}

\tiny
Gigerenzer, G., Krauss, S., \& Vitouch, O. (2004). The null
ritual. In D. Kaplan (Ed.), \emph{The Sage book of quantitative
methodology for the social sciences} (pp. 391–408).
Thousand Oaks, CA: Sage.
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Neyman \& Pearson scheme}

\small
\begin{columns}

\begin{column}{.65\textwidth}

\begin{enumerate}
  \item Set up two statistical hypotheses, $H_1$ and $H_2$, and decide on $\alpha$ (Type 1 error rate), $\beta$ (Type 2 error rate), and the sample size before the experiment, based on subjective cost-benefit considerations.
  \item If the data fall into the rejection region of $H_1$, accept $H_2$; otherwise accept $H_1$.
  \item The usefulness of this procedure is limited among others to situations where there is a disjunction of hypotheses (e.g., either $\mu_1$ or $\mu_2$ is true), where there is repeated sampling, and where you can make meaningful cost-benefit trade-offs for choosing $\alpha$ and $\beta$.
\end{enumerate}

\end{column}
\begin{column}{.15\textwidth}
\scalebox{.25}{\includegraphics{img/neypea.png}}
\end{column}
\begin{column}{.1\textwidth}

\end{column}

\end{columns}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Fisher null hypothesis testing}

\vspace{-.3cm}
\begin{footnotesize}
 \begin{flushright}
        \emph{No scientific worker has a fixed level of significance at which from year to year, and in all circumstances, he rejects hypotheses; he rather gives his mind to each particular case in the light of his evidence and his ideas.} (Fisher, 1956)
    \end{flushright}
\end{footnotesize}


\begin{columns}

\begin{column}{.65\textwidth}

\begin{enumerate}
  \item Set up a statistical null hypothesis. The null need not be a nil hypothesis (e.g., zero difference).
  \item Report the exact level of significance (e.g., $p = .055$ or .045). Do not use a conventional 5\% level all the time.
  \item Use this procedure only if you know little about the problem at hand.
\end{enumerate}

\end{column}

\begin{column}{.15\textwidth}
\scalebox{.13}{\includegraphics{img/ronaldfisher.jpg}}
\end{column}
\begin{column}{.1\textwidth}

\end{column}

\end{columns}

\vspace{.3cm}
\noindent\rule{5cm}{0.4pt}

\tiny
Fisher, R. A. (1956). \emph{Statistical methods and scientific inference}. Edinburgh, UK: Oliver \& Boyd.
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Limiti dell'approccio NHST}
\begin{frame}{\textbf{Limiti dell'approccio NHST}}

\vspace{-.3cm}
\begin{footnotesize}
 \begin{flushright}
        \emph{Statistical signifcance is not a scientific test. It is a
philosophical, qualitative \\ test.  It does not ask how much. It asks whether. Existence, the question
of\\ whether, is interesting. But it is not scientific.}
        (Ziliak \& McCloskey, 2008)
    \end{flushright}
\end{footnotesize}
Nell'utilizzo dell'approccio NHST bisogna assolutamente tenere conto dei seguenti aspetti: \pause[]
\begin{itemize}
  \item NHST tende a indurre confusione tra la probabilit\`a dell'ipotesi condizionata
ai dati (probabilit\`a a posteriori) e probabilit\`a dei dati condizionati all'ipotesi (verosimiglianza). \pause[]
  \item NHST viene erroneamente considerato un metodo per la verifica delle ipotesi. In realt\`a esso tiene conto solo di $H_0$ e permette solo la falsificazione di tale ipotesi senza che questo abbia relazione con la veridicit\`a di $H_1$.
\end{itemize}


\noindent\rule{5cm}{0.4pt}

\tiny
Ziliak, S. T., \& McCloskey, D. N. (2008). \emph{The cult of statistical significance}. Ann Arbor, MI: University of Michigan Press.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Limiti dell'approccio NHST}}
\begin{itemize}
  \item Il criterio $\alpha = 0.05$ \`e puramente arbitrario ed è stato più volte messo in discussione (es. Johnson, 2013; Benjamin \& al., 2017; Lakens, 2018) \pause[]
  \item I test tradizionali tendono a sovrastimare l'evidenza contro $H_0$: infatti $H_0$ nei contesti
reali non \`e mai esattamente vera e pertanto aumentando a dovere il numero di osservazioni \`e quasi
sempre possibile rigettarla (Wagenmakers, 2007).
\end{itemize}

\noindent\rule{5cm}{0.4pt}

\tiny
Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E. J., Berk, R., $\ldots$ \& Cesarini, D. (2018). Redefine statistical significance. \emph{Nature Human Behaviour}, 2(1), 6--10.

Johnson, V. E. (2013). Revised standards for statistical evidence. \emph{Proceedings Of The National Academy Of Sciences Of The United States Of America}, 110, 19313–19317.

Lakens, D. (2018). Justify Your Alpha by Decreasing Alpha Levels as a Function of the Sample Size, disponibile on-line: \url{http://daniellakens.blogspot.com/2018/12/testing-whether-observed-data-should.html}

Wagenmakers, E. J. (2007). A practical solution to the pervasive problems of $p$ values. \emph{Psychonomic Bulletin \& Review}, 14, 779–804.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Limiti dell'approccio NHST}}

\begin{columns}
\begin{column}{0.4\textwidth}
\begin{itemize} \small
 \item L'ipotesi nulla legata ad un unico valore puntuale può portare a conclusioni improprie (Berger \& Sellke, 1987; Sellke, Bayarri \& Berger, 2001).
 \item Ad esempio, se: $H_0: \mu=0$ \pause[2] $$P(\mu=0)= \pause[3] 0$$
\end{itemize}
\end{column}
\begin{column}{0.6\textwidth} \pause[1]
<<fig.width=2.5,fig.height=2.5>>= %,
ggplot()+theme_bw()+stat_function(fun=dnorm,color ="#222255",lwd=1.2) + scale_x_continuous(limits = c(-3,3))+scale_y_continuous(limits=c(0,.45),labels=NULL)+geom_vline(xintercept=0,lty=2,lwd=1)+xlab("")+ylab("") #+theme(text=element_text(size=2))
@

\end{column}
\end{columns}

%\vspace{1cm}
\noindent\rule{5cm}{0.4pt}

\tiny
Berger, J. O., \& Sellke, T. (1987). Testing a Point Null Hypothesis: The Irreconcilability of P Values and
Evidence. \emph{Journal of the American Statistical Association}, 82(397), pp. 112–122.

Sellke, T., Bayarri, M., \& Berger, J. O. (2001). Calibration of $p$ values for testing precise null hypotheses. \emph{The American Statistician}, 55(1), 62–71.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Il paradosso del $t$-test}
\begin{frame}{Il paradosso del $t$-test (Rouder \& al, 2009)}

<<echo=FALSE,results='hide'>>=

load(paste(datadir,"RouderMC.rda",sep=""))

@
\begin{itemize}
\item Consideriamo un esperimento in cui \Sexpr{nrow(Z1)} soggetti rispondono a \Sexpr{ncol(Z1)} stimoli in due condizioni diverse. Per ciascun soggetto avremo pertanto 200 tempi di reazione (TR).
\item Assumiamo che per ciascun soggetto la media dei TR sia compresa tra 500 e 1000 ms, con una deviazione standard di 300.
\item Siano $x_{1i}$ e $x_{2i}$, $i=\{1,...,n\}$ le medie dei TR nelle due condizioni per ciascun soggetto.
\item Vogliamo confrontare questi valori per stabilire se esista una differenza significativa tra le medie nelle due condizioni.

\end{itemize}


\vspace{.5cm}
\noindent\rule{5cm}{0.4pt}

\tiny{Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., \&
Iverson, G. (2009). Bayesian t tests for accepting and
rejecting the null hypothesis. \emph{Psychonomic Bulletin \&
Review}, 16, 225–237.}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Il paradosso del $t$-test (Rouder \& al, 2009)}

<<echo=FALSE,fig.show='hide'>>=
x1 <- apply(Z1,2,mean)
x2 <- apply(Z2,2,mean)
X <- stack(data.frame(x1,x2))
Ttest <- t.test(x2,x1,paired=TRUE)
gl <- as.numeric(Ttest$parameter)
@

\footnotesize
Confrontando le medie nelle due condizioni otteniamo il seguente risultato:\\
\vspace{-.3cm}
<<echo=FALSE,results='markup',comment=NA>>=
t.test(x2,x1,paired=TRUE)
@
\vspace{-.3cm}
con una differenza tra le medie pari a circa 11ms.

\pause[]
\vspace{.1cm}
Un modo per quantificare l'evidenza del risultato consiste nel calcolare la verosimiglianza del valore osservato di $t$ (\Sexpr{round(Ttest$statistic,3)}) sotto varie ipotesi alternative.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Verosimiglianza}

\begin{columns}
\begin{column}{0.6\textwidth}
<<fig.width=2.5,fig.height=2.8>>=
tval <- Ttest$statistic
x <- seq(-3,3,.01)
d <- data.frame(x)
d$y <- dt(x,99)
ggplot(d,aes(x,y)) +theme_bw() + geom_line(linewidth = 1.2) +xlab("$t$")+ylab("$d(t)$") + annotate("segment",x=-3,y=dt(tval,99),xend=tval,yend=dt(tval,99),col="red",lty=3,lwd=1.2) + annotate("segment", x=tval,xend=tval,y=0,yend=dt(tval,99),col="red",lty=3,lwd=1.2)+ annotate("point", tval,dt(tval,99),col="red",size=POINTCEX,pch=19)

@
\end{column}

\begin{column}{0.4\textwidth}
\footnotesize{
Il valore di verosimiglianza di $t=\Sexpr{round(Ttest$statistic,3)}$ sotto l'ipotesi $H_{0}$ \`{e} dato dalla densit\`{a} della distribuzione $t$ con \Sexpr{gl} gradi di libert\`{a}, cio\`{e} circa \Sexpr{round(dt(Ttest$statistic,gl),3)}.
\vspace{.3cm}

Se $H_{0}$ \`{e} vera vuol dire che non esiste differenza tra i TR nelle due condizioni.
\vspace{.3cm}

Formalmente $H_{0}:\mu_{2}-\mu_{1}=0$.
}
\end{column}
\end{columns}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Rapporto di verosimiglianza}

\begin{columns}

\begin{column}{0.6\textwidth}
<<fig.width=2.5,fig.height=2.8>>=
N <- length(x1)
my <- 30
sy <- sd(x2-x1)
nc.par <- sqrt(N)*my/sy

ggplot(d,aes(x,y))+theme_bw()+stat_function(fun=dt,args=list(df=99),lwd=.3,col=grey(.6))+xlab("$t$")+ylab("$d(t)$")+stat_function(fun=dt,args=list(df=99,ncp=nc.par),lwd=1.2)+ geom_vline( xintercept = tval, lty = 3) + scale_x_continuous(limits=c(-3,10)) + annotate("segment",x=-3,y=dt(tval,99,nc.par),xend=tval,yend=dt(tval,99,nc.par),col="red",lwd=1.2) + annotate( "segment", x=tval,xend=tval,y=0,yend=dt(tval,99,nc.par),col="red",lty=2,lwd=1.2) + annotate("point", tval,dt(tval,99,nc.par),col="red",size=POINTCEX,pch=19) + annotate("point", tval,dt(tval,99),col=grey(.6),size=POINTCEX,pch=19)
@
\end{column}

\begin{column}{0.48\textwidth}
\footnotesize{
Supponiamo che la reale differenza tra i TR sia invece pari a 30ms e calcoliamo il relativo valore di verosimiglianza per $t=2.2419$ sotto l'ipotesi $H_{1}:\mu_{2}-\mu_{1}=30$.
\vspace{.3cm}

Tale valore
 \`{e} dato dalla densit\`{a} della distribuzione $t$ con 99 gradi di libert\`{a} e parametro di noncentralit\`{a} $\sqrt{N}\frac{\Delta_{\mu}}{\sigma_{\Delta_{\mu}}}$ (circa 5.86) ed \`{e} inferiore a 0.001.
\vspace{.3cm}

\pause[]
\begin{beamerboxesrounded}[upper=upnotabene,lower=lonotabene, shadow=true]{}
Il rapporto di verosimiglianza tra $L(H_{0})$ e $L(H_{1})$ risulta di 48 a 1 in favore di $H_{0}$, nonostante il test sia risultato statisticamente significativo (!!!!).
\end{beamerboxesrounded}
}
\end{column}
\end{columns}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Likelihood Ratio}

\begin{columns}
\begin{column}{0.62\textwidth}
<<LRT,fig.width=2.8,fig.height=2.8,warning=FALSE>>=
L0 <- dt(tval,99)
L1 <- dt(tval,99,nc.par)
my <- seq(0,40,.01)
NC.par <- sqrt(N)*my/sy
y <- L0/dt(tval,99,NC.par)
d <- data.frame(my,y)
Y <- round(L0/L1)

x1 <- 10.5
y1 <- 0.05
x2 <- 32
y2 <- y1
SIZEh <- 2.2

ggplot(d,aes(my,y))+theme_bw()+xlab("Alternative (ms)")+ylab("Likelihood Ratio (null/alternative)")+geom_hline(yintercept=Y,col="#0080ff",lty=2,lwd=1.2)+geom_vline(xintercept = 30,col="#0080ff",lty=2,lwd=1.2)+geom_hline(yintercept = 1,col=gray(.6),lty=3,lwd=1.2)+geom_vline(xintercept=23,col=gray(.6),lty=3,lwd=1.2)+geom_line(col="blue",lwd=1.2)+scale_y_continuous(trans="log2",breaks=c(.1,10,Y,1000,100000),label=c(.1,10,Y,1000,100000),limits=c(0.05,100000))  + annotate("text", x1, y1, label = "\\textbf{Favours the alternative}", size = SIZEh)  + annotate("text", x2, y2, label = "\\textbf{Favours the null}", size = SIZEh) + theme(text = element_text(size=SIZEh*3.2))

@
\end{column}

\begin{column}{0.43\textwidth}
\footnotesize{
Rappresentiamo graficamente il rapporto di verosimiglianza tra $H_{0}$ e diversi valori di ipotesi alternativa, fino a 40ms.
\vspace{.3cm}
\pause[]

\begin{beamerboxesrounded}[upper=upnotabene,lower=lonotabene, shadow=true]{\textbf{Si osserva il seguente paradosso}:}
    l'ipotesi $H_{0}$ risulta essere pi\`{u} verosimile rispetto all'ipotesi alternativa per differenze superiori a 23ms.
    \end{beamerboxesrounded}
}
\end{column}
\end{columns}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{Interpretazione del $p$-\emph{value}: 7 marzo 2016}}

\scalebox{.45}{\includegraphics{img/ASA.png}}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\begin{center}
\scalebox{2}{\includegraphics{img/Cassidy_et_al_2019.png}}

\footnotesize{(\emph{Advances in Methods and Practices in Psychological Science}, 2019)}
\end{center}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\begin{center}
\scalebox{.23}{\includegraphics{img/McShane&al_2019.png}}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}

  \begin{beamerboxesrounded}
{}
\textbf{Abandon the idea that the goal of the statistical analysis is to get some sort of certainty. Instead, accept posterior ambiguity: don’t try to learn more from the data than you really can.}

\begin{flushright}
(Andrew Gelman, 2018)
\end{flushright}

\end{beamerboxesrounded}

\pause \vspace{.5cm}
  \begin{beamerboxesrounded}
{}
\textbf{Accept uncertainty. Be thoughtful, open, and
modest. Remember ``ATOM''.}

\begin{flushright}
(Wasserstein, Schirm \& Lazar, 2019)
\end{flushright}

\end{beamerboxesrounded}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\begin{center}
\scalebox{.4}{\includegraphics{img/retire.png}}
\end{center}

\begin{flushright}
NATURE, 21 March 2019
\end{flushright}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{}

\begin{center}
\scalebox{2}{\includegraphics{img/Amrhein_descriptive.png}}
\end{center}

\begin{flushright}
The American Statistician, 2019
\end{flushright}


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{Interpretazione del $p$-\emph{value}}}

\begin{beamerboxesrounded}[upper=uppercolor, lower=loesempio, shadow=true]
    {\textbf{In sostanza:}}
    \begin{itemize}
      \item $p$-\emph{value} \`{e} la probabilit\`{a} di ottenere un risultato uguale o pi\`{u} estremo rispetto a quello rilevato empiricamente se (e solo se) l'ipotesi $H_0$ \`{e} vera. \pause[]
      \item Non rappresenta in alcun modo la probabilit\`{a} che sia vera $H_0$ e pertanto non pu\`{o} essere considerato un misuratore del grado di falsit\`{a} della stessa. \pause[]
      \item $p$-\emph{value} risente della numerosit\`{a} campionaria: pi\`{u} aumenta $n$ pi\`{u} tende a diminuire. \pause[]
      \item Non \`{e} una misura dell'evidenza statistica, va usato solo come criterio decisionale per rigettare o meno $H_0$.
    \end{itemize}
\end{beamerboxesrounded}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{\textbf{Interpretazione del $p$-\emph{value}}}


\begin{center}
  \scalebox{1}{\includegraphics{img/lakens_2021.png}}
\end{center}

\begin{flushright}
(Lakens, 2021)
\end{flushright}

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Bayes]{Inferenza bayesiana}
\begin{frame}[plain]

\begin{beamerboxesrounded}[upper=title, lower=structure, shadow=true]
    {\center{\Large{\textbf{Inferenza in senso bayesiano}}}}
\end{beamerboxesrounded}

\end{frame}

\begin{frame}{Inferenza Bayesiana}

\begin{scriptsize}
 \begin{flushright}
        \emph{A frequentist is a person whose long-run \\ambition is to be wrong 5\% of the time.\\ A Bayesian is one who, vaguely expecting a horse, \\and catching a glimpse of a donkey, \\strongly believes he has seen a mule.}

    \end{flushright}
\end{scriptsize}


 \begin{itemize}
  \item Nonostante il teorema di Bayes sia storicamente pi\`u antico (risale circa alla met\`a del '700) la sua affermazione in un approccio statistico alternativo pu\`o essere datata verso la met\`a degli anni '60 ad opera di Lindley.
  \item La ragione di questo \emph{ritardo} è da imputare a due principali ragioni, una storica ed una tecnologica.
 \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Inferenza Bayesiana}

 \begin{itemize}
  \item Negli ultimi anni è cresciuta una \emph{corrente Bayesiana}, anche nell'ambito della psicologia (es. Dienes and Mclatchie,2018; Etz and Vandekerckhove, 2018; Kruschke and Liddell, 2018).
  \item Vi sono almeno tre ragioni che possono spiegare questo fatto:
      \begin{enumerate}
       \item L'approccio Bayesiano permette una valutazione delle ipotesi in termini di evidenza.
       \item Pu\`o essere utilizzato anche in casi di elevata complessit\`a.
       \item Molti software statistici hanno ormai implementato la possibilt\`a di fare analisi in senso Bayesiano.
      \end{enumerate}

 \end{itemize}

\noindent\rule{5cm}{0.4pt}

\tiny
Dienes, Z., \& Mclatchie, N. (2018). Four reasons to prefer Bayesian analyses over significance testing. \emph{Psychonomic Bulletin \& Review}, 25(1), 207–218.

Etz, A., \& Vandekerckhove, J. (2018). Introduction to Bayesian inference for psychology. \emph{Psychonomic Bulletin \& Review}, 25(1), 5–34.

Kruschke, J. K., \& Liddell, T. M. (2018b). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. \emph{Psychonomic Bulletin \& Review}, 25(1), 178–206.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{}
\begin{frame}{Approccio bayesiano vs NHST}
\begin{itemize}
 \item Nell'approccio  NHST i parametri (quasi sempre incogniti) sono considerati come quantit\`a fisse.
 \item Nell'approccio bayesiano invece, i parametri sono trattati come variabili
casuali con una distribuzione di probabilit\`a.
\end{itemize}

\vspace{.3cm}
\begin{beamerboxesrounded}[upper=upesempio,lower=loesempio]{Esempio:}
\begin{itemize}
 \item Supponiamo che $\mu$ indichi la media (incognita) di una popolazione.
 \item Con l'approccio bayesiano possiamo stimare ad esempio $P(\mu<T)$, $P(T_1<\mu<T_2)$.
 \item Con l'approccio classico questo non \`e possibile in quanto la
probabilit\`a che la media vera sia inferiore a $T$ \`e $0$ oppure $1$.
\end{itemize}
\end{beamerboxesrounded}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Sistema di Ipotesi}
\begin{itemize}
 \item Nel sistema di ipotesi bayesiano viene definita una distribuzione a
priori per il parametro oggetto del test.
 \item Questa distribuzione viene combinata con le informazioni derivate dai
dati (verosimiglianza) per ottenere una distribuzione a posteriori.
 \item Formalmente: $$\mbox{posterior} \propto \mbox{prior} \times
\mbox{likelihood} $$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{}
\begin{frame}{\textbf{Problema \Sexpr{nprob}}} % toglinelprint
<<>>=
nprob <- nprob+1
@
\begin{beamercolorbox}[rounded=true, shadow=true]{loesempio}
\textbf{Vogliamo stimare la percentuale (o la proporzione) di studenti iscritti ai corsi della Scuola di Psicologia a cui piace la Statistica, ma questa volta utilizzando una procedura di stima bayesiana.
}
\end{beamercolorbox}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Definizione della \emph{prior}}}

\begin{itemize}
 \item Sia $\theta=p(\mbox{piace})$.
 \item Come primo passo dobbiamo definire i nostri \emph{prior beliefs}.
 \item Secondo NHST siamo abituati a definire solo l'ipotesi $H_0:\theta=.5$
 \item In questo caso possiamo fare una operazione molto più raffinata, ovvero individuare più valori possibili di $\theta$ ed assegnare a ciascuno di essi una probabilità $p(\theta)$.
\end{itemize} \pause
\vspace{-.1cm}
\begin{beamercolorbox}[rounded=true, shadow=true,ht=.5cm]{loesempio} %,colsep*=-8pt ,wd=.9\textwidth
\begin{itemize}
 \item \textbf{Sondaggione}
\end{itemize}
\end{beamercolorbox}

<<binomial_prior>>=

PRIORFREQ <- c( 7, 23, 9, 4, 1, 0, 0, 0, 0 )
theta <- c( 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ) # valori del parametro
tabfreq <- PRIORFREQ
prior <-  tabfreq / sum(tabfreq) # probabilità a priori
data <- c(rep(1,n_piace),rep(0,n-n_piace))
n <- length(data)
n_piace <- sum(data)
L <- theta^n_piace*(1-theta)^(n-n_piace)
pData <- sum(prior*L)
post <- prior*L/pData
TT <- data.frame(theta,prior,L,post)
XLIM <- c(0,1)
BREAKS <- seq(0,max(TT$L),length.out = 5)
@
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Definizione della \emph{prior}}}

\begin{center}

MENTIMETER
% \scalebox{1}{\includegraphics{img/Quanto_piace_la_statistica.png}}
\end{center}


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Definizione della \emph{prior}}} % toglinelprint

<<results="markup">>=
cat("# valori del parametro","\n")
cat("> theta <- c(",paste(theta,collapse = ", "),")","\n")
@

\pause
<<results="markup">>=
cat("# probabilità a priori","\n")
cat(paste0("> (prior <- c(",paste( tabfreq ,collapse = ", "),") / ",sum(tabfreq),")"),"\n")
@
\vspace{-.6cm} \pause
<<results='markup'>>=
round( prior, 2)
@
\pause %\vspace{-.5cm}
<<echo=TRUE,fig.keep="none">>=
plot( theta, prior, type = "h", lwd = 3,
        xlim = c( 0, 1 ), ylim = c( 0, 1 ) )
@

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame} % toglinelprint %{\textbf{Definizione della \emph{prior}}}

\vspace{.3cm}
<<>>=
TEXTCEX <- TEXTCEX + 3
LWD <- LWD+.2

(GGPRIOR <- ggplot(TT,aes(theta,prior))+theme_bw()+geom_point(size=POINTCEX)+geom_segment(aes(xend=theta,yend=0),linewidth=LWD,color="#161883")+scale_x_continuous(limits=XLIM,breaks=c(0,theta,1))+xlab("$\\theta$")+ylab("$p(\\theta)$")+ggtitle("Prior")+theme(plot.title=element_text(hjust=.5),text=element_text(size=TEXTCEX)))
@

%\vspace{-.6cm}
\begin{itemize} \footnotesize
 \item

 Abbiamo scelto \Sexpr{length(theta)} valori plausibili per $\theta$ nella popolazione, a ciascuno dei quali è stata assegnata una probabilità $p(\theta)$.
\end{itemize}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Definizione della \emph{likelihood}}} % toglinelprint

\begin{itemize}
 \item A questo punto \emph{prendiamo in esame i dati}, su \Sexpr{n} partecipanti, a \Sexpr{n_piace} piace la statistica, a \Sexpr{n-n_piace} non piace.
 \item Sulla base di questo risultato possiamo calcolare i valori di \emph{likelihood} relativi a ciascuno dei  \Sexpr{length(theta)} valori di $\theta$ con la formula seguente:
\end{itemize}

\begin{beamercolorbox}[colsep*=-8pt,rounded=true,shadow=true,ht=.8cm,center]{formula}
\begin{center} %sep=0em,
$p(D|\theta) = \theta^{\Sexpr{n_piace}} (1-\theta)^{\Sexpr{n-n_piace}}$
\end{center}
\end{beamercolorbox}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Definizione della \emph{likelihood}}} % toglinelprint

\begin{beamercolorbox}[colsep*=-8pt,rounded=true,shadow=true,ht=.9cm,center]{formula}
\begin{center} %sep=0em,
$p(D|\theta) = \theta^{\Sexpr{n_piace}} (1-\theta)^{\Sexpr{n-n_piace}}$
\end{center}
\end{beamercolorbox}

<<results='markup'>>=
cat(paste0("> (L <- theta ^ ",n_piace," * ( 1 - theta ) ^ ",n - n_piace,")"),"\n")
@
\vspace{-.6cm} \pause
<<results='markup'>>=
options(width=80)
cat(paste0("[1] ",paste(formatC(L[1:5],2),collapse=" ")),"\n")
cat(paste0("[6] ",paste(formatC(L[5:length(L)],2),collapse=" ")),"\n")
@
\vspace{-.5cm} \pause
<<echo=TRUE,fig.keep="none">>=
plot( theta, L, type = "h", lwd = 3, xlim = c( 0, 1 ))
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame} % toglinelprint %{\textbf{Definizione della \emph{likelihood}}}

\vspace{1cm}
<<binomial_like>>=
(GGLIKE <- ggplot(TT,aes(theta,L))+theme_bw()+geom_point(size=POINTCEX)+geom_segment(aes(xend=theta,yend=0),linewidth=LWD,color="#161883")+scale_x_continuous(limits=XLIM,breaks = c(0,theta,1))+xlab("$\\theta$")+ylab("$p(D|\\theta)$")+ggtitle("Likelihood")+theme(plot.title=element_text(hjust=.5),text=element_text(size=TEXTCEX))+scale_y_continuous(limits = c(0,max(TT$L)),labels=formatC(BREAKS,1),breaks = BREAKS))
@

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Calcolo della \emph{posterior}}} % toglinelprint

\begin{itemize}
 \item Per il calcolo della distribuzione a posteriori utilizziamo infine il teorema di Bayes:
\end{itemize}

\begin{beamercolorbox}[colsep*=-8pt,rounded=true,shadow=true,ht=.9cm,center]{formula}

\begin{center} %sep=0em,
$p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}$
\end{center}
\end{beamercolorbox} \pause

\begin{itemize}
 \item Nel caso binomiale il calcolo di $p(D)$ è piuttosto semplice ovvero:
\end{itemize}
\begin{beamercolorbox}[colsep*=-8pt,rounded=true,shadow=true,ht=.8cm,center]{formula}
\begin{center} %sep=0em,
$p(D)=\sum_{\theta} p(D|\theta)p(\theta)$
\end{center}
\end{beamercolorbox}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Calcolo della \emph{posterior}}} % toglinelprint

\begin{beamercolorbox}[colsep*=-8pt,rounded=true,shadow=true,ht=.8cm,center]{formula}
\begin{center} %sep=0em,
$p(D)=\sum_{\theta} p(D|\theta)p(\theta)$
\end{center}
\end{beamercolorbox}

\vspace{-.6cm}
<<echo=TRUE,results="hide">>=
( pData <- sum( L * prior ) )
@
\vspace{-.6cm} \pause
<<results='markup'>>=
cat(paste("[1]",formatC(pData,3)),"\n")
@
\pause
\begin{beamercolorbox}[colsep*=-8pt,rounded=true,shadow=true,ht=.9cm,center]{formula}
\begin{center} %sep=0em,
$p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}$
\end{center}
\end{beamercolorbox} \pause

\vspace{-.6cm}
<<echo=TRUE,results="hide">>=
( post <- L * prior / pData )
@
\vspace{-.6cm} \pause
<<results='markup'>>=
cat(paste0("[1] ",paste(formatC(post,2),collapse=" ")),"\n")
@
\vspace{-.5cm} \pause
<<echo=TRUE,fig.keep="none">>=
plot( theta, post, type = "h", lwd = 3,
      xlim = c( 0, 1 ), ylim = c( 0, 1 ) )
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame} % toglinelprint %{\textbf{Calcolo della \emph{posterior}}}

\vspace{1cm}
<<binomial_post>>=
(GGPOST <- ggplot(TT,aes(theta,post))+theme_bw()+geom_point(size=POINTCEX)+geom_segment(aes(xend=theta,yend=0),linewidth=LWD,color="#161883")+scale_x_continuous(limits=XLIM,breaks = c(0,theta,1))+xlab("$\\theta$")+ylab("$p(\\theta|D)$")+ggtitle("Posterior")+theme(plot.title=element_text(hjust=.5),text=element_text(size=TEXTCEX)))
@

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Riassumendo}}

<<>>=
TEXTSIZE <- 8; YLIM <- c(0,max(post))
POINTCEX <- 1

GGPRIOR$layers[[1]] <- GGLIKE$layers[[1]] <- GGPOST$layers[[1]] <-NULL

cowplot::plot_grid(
  GGPRIOR+geom_point(size=POINTCEX)+theme(text=element_text(size=TEXTSIZE),title = element_text(size=TEXTSIZE*.9))+scale_y_continuous(limits=YLIM),
  GGLIKE+geom_point(size=POINTCEX)+theme(text=element_text(size=TEXTSIZE),title = element_text(size=TEXTSIZE*.9)),
  GGPOST+geom_point(size=POINTCEX)+theme(text=element_text(size=TEXTSIZE),title = element_text(size=TEXTSIZE*.9))+scale_y_continuous(limits=YLIM), ncol = 1
)
@



\end{frame}

%%%%%%%%%%%%%%%%
\part{}
\section{Approcci a confronto}
\begin{frame}[plain]

\begin{beamerboxesrounded}[upper=title, lower=structure, shadow=true]
    {\center{\Large{\textbf{Approcci a confronto}}}}
\end{beamerboxesrounded}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%
\subsection{Approccio bayesiano vs NHST}
\begin{frame}{\textbf{Approccio bayesiano vs NHST}}
\small
\begin{itemize}
\item Una differenza fondamentale tra NHST ed i metodi bayesiani \`e il modo di trattare i parametri (incogniti). Nel primo caso infatti essi vengono considerati come quantit\`a fisse mentre nel secondo sono trattati come variabili casuali con una distribuzione di probabilit\`a associata.
\end{itemize}

<<>>=
set.seed(6)
data(gambling, package = "ADati")
n <- 16;
gambling$ID <- as.character(gambling$ID)
Im <- sample( subset(gambling, gender=="m" & frequency > 7.5 )$ID, n/2)
If <- sample( subset(gambling, gender=="f" & frequency <12.5)$ID, n/2)
Y <- subset( gambling, ID %in% c(Im,If) )
MX <- aggregate(frequency ~ gender, data = Y, FUN = mean)
SX <- aggregate(frequency ~ gender, data = Y, FUN = sd)
Yf <- round(Y$frequency[Y$gender=="f"],1)
Ym <- round(Y$frequency[Y$gender=="m"],1)
sigma <- sd(Y$frequency)
#t.test( Ym, Yf, alternative = "greater", var.equal = TRUE)
#t.test(frequency ~ gender, data = Y, var.equal=TRUE)
# with( Y, effectsize::cohens_d(frequency[gender=="m"],frequency[gender=="f"]))
@
\vspace{.3cm} \pause
\begin{beamerboxesrounded}[upper=upesempio,lower=loesempio, shadow=true]
{\textbf{Problema \Sexpr{nprob}}}
Consideriamo un campione di \Sexpr{n} soggetti, di cui \Sexpr{sum(Y$gender=="m")} maschi, di età intorno ai \Sexpr{round(mean(Y$age))} anni intervistati rispetto alla loro propensione al gioco d'azzardo -- calcolata con la frequenza di partecipazione a diversi tipi di gioco (es. scommesse sportive o slot machines) in cui punteggi più alti indicano una maggiore tendenza al gioco d'azzardo.
Ci chiediamo se ci sia una differenza di genere su tale propensione.

\end{beamerboxesrounded}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Dati campionari}} % toglinelprint


I punteggi osservati sono i seguenti:
<<results='markup'>>=
cat(paste0("> Ym <- c( ",paste( Ym , collapse = ", ")," )"),"\n")
@
per i maschi e
<<results='markup'>>=
cat(paste0("> Yf <- c( ",paste( Yf, collapse = ", ")," )"),"\n")
@
per le femmine.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Statistiche del campione}} % toglinelprint


\begin{itemize}
  \item Soggetti: $n=\Sexpr{n}$
  \item Medie campionarie: \pause
<<results='markup'>>=
cat("> c( mean(Ym), mean(Yf) ) ","\n")
round( c( mean(Ym), mean(Yf) ), 2 )
@
  \item Deviazioni standard: \pause
<<results='markup'>>=
cat("> c( sd(Ym), sd(Yf) ) ","\n")
round( c( sd(Ym), sd(Yf) ), 2 )
@
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{\textbf{Problema \Sexpr{nprob}}}
<<>>=
nprob <- nprob+1
@
\begin{beamercolorbox}[rounded=true, shadow=true]{loesempio}
\textbf{Sulla base dei dati osservati, possiamo considerare questi soggetti come provenienti da due popolazioni con la stessa media $\mu_m = \mu_f = \mu$?
}
\end{beamercolorbox}

\vspace{.3cm}
\begin{itemize} \pause
\item In ottica NHST quello che possiamo fare è definire il seguente sistema di ipotesi:
\begin{eqnarray*}
\begin{array}{l}
H_0: \pause \mu_m=\mu_f \\
H_1: \pause \mu_m > \mu_f
\end{array}
\end{eqnarray*}
\end{itemize}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{}
\begin{frame}%{\textbf{Approccio bayesiano vs NHST}}

<<>>=
se_diff <- sqrt(var(Ym)/length(Ym)+var(Yf)/length(Yf))
tval <- (mean(Ym)-mean(Yf))/ se_diff
@

\begin{itemize}
\item Sappiamo che la distribuzione campionaria della differenza tra le medie standardizzate sotto $H_0$ $$\frac{\overline{x}_m-\overline{x}_f}{\sigma_{\overline{x}_m-\overline{x}_f}} \sim \pause  \mbox{Student } t_{(n-2)}$$ \pause
\item Nel caso in esame:

$$\frac{ \Sexpr{round(mean(Ym),2)}-\Sexpr{round(mean(Yf),2)} }{ \Sexpr{round(se_diff,2)} } = \Sexpr{ round(tval,2) }$$
  \end{itemize}

\vspace{1cm}
\rule{5cm}{.01cm}

  \scriptsize
L'errore standard della differenza tra le medie si calcola con $\sqrt{\frac{\sigma^2_m}{n_m} + \frac{\sigma^2_f}{n_f}}$.


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] % toglinelprint

<<results='markup'>>=
cat(paste0("> curve( dt( x, ",n-2," ), -4, 4 )"),"\n")
@
\pause
<<>>=
Z <- data.frame(x=seq(-4,4,by=.01))
Z$y <- dt(Z$x,n-2)

(PLOT <- ggplot(Z,aes(x,y))+theme_bw()+geom_line()+xlab("$t$")+ylab("$f(t|H_0)$"))
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] % toglinelprint

<<results='markup'>>=
cat(paste0("> points( ",round(tval,2),", 0, pch = 19, col = 'red' )"),"\n")
@

\pause
<<>>=
POINTCEX <- 2
PLOT + annotate("point",x=tval,y=0, colour="red", size=POINTCEX)
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] % toglinelprint

\vspace{-.2cm}
<<results='markup'>>=
cat(paste0("> pt( ",round(tval,2),", ",n-2,", lower.tail = FALSE ) "),"\n")
@
\pause \vspace{-.5cm}
<<results='markup'>>=
pt(tval, n-2, lower.tail = FALSE)
@

\pause \vspace{-.1cm}
<<>>=
Z$ycrit <- with(Z, ifelse( x<tval, NA, y ))
ggplot(Z,aes(x,y))+theme_bw() + geom_ribbon(aes(ymin=0,ymax=ycrit), data=Z, fill="#ff7f50") + annotate("point", x=tval,y=0, colour="red", size=POINTCEX)+geom_line()+xlab("$t$")+ylab("$f(t|H_0)$")
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] % toglinelprint

 %\vspace{.5cm}
\begin{beamercolorbox}[rounded=true, shadow=true]{formule}
\textbf{Questo test statistico è noto come \pause test $t$ di Student.}
\end{beamercolorbox}

\pause
<<echo=TRUE, eval=FALSE>>=
t.test( Ym, Yf, alternative = "greater",
                var.equal = TRUE )
@
\pause \vspace{-.5cm}
<<results='markup'>>=
L <- capture.output(t.test( Ym, Yf, var.equal = TRUE, alternative = "greater" ))
L <- gsub("\t","     ",L)

riga <- grep("alternative",L)
L <- L[c(1:riga,riga:length(L))]
L[riga] <- substr(L[riga],1,23)
L[riga+1] <- gsub("alternative hypothesis:","    ",L[riga+1])
for (j in 1:length(L)) cat(L[j],"\n")
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{}
\begin{frame}%{\textbf{Approccio bayesiano vs NHST}}
\small
\begin{itemize}
\item In ottica bayesiana la differenza $\mu_m - \mu_f = \delta$ è considerata come variabile casuale con una sua distribuzione e, di conseguenza, è possibile stimare una probabilità sia per $H_0$, che per $H_1$ e stabilire quale delle due ipotesi risulti più verosimile.
\item In altre parole, con un metodo bayesiano possiamo calcolare $Pr(\delta > 0)$, mentre con NHST tale probabilità può essere solo 0 ($H_1$ \`e falsa) oppure 1 ($H_1$ \`e vera).
\item In particolare, utilizzando la distribuzione a posteriori di $\delta$ possiamo calcolare la probabilità associata a qualunque ipotesi ci interessi.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{\textbf{Posterior distribution}} % toglinelprint

\vspace{-.3cm}
<<fig.keep='none',echo=TRUE, message=FALSE>>=
library( BayesFactor )
samples <- ttestBF( Ym, Yf, posterior = TRUE,
                   iterations = 1e5 )
plot( density( samples[, "delta"] ) )
@
\pause
<<message=FALSE,fig.height=2>>=
par( ask = FALSE)
library(BayesFactor)
samples <- ttestBF(Ym, Yf, posterior = TRUE, iterations = 1e5)
B <- length(samples[,"delta"])

DD <- density(samples[,"delta"],n=1000)
post <- data.frame( x = DD$x, y = DD$y )
ggplot(post,aes(x,y))+theme_bw()+geom_line()+xlab("$\\delta$") + ylab("")
@
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] % toglinelprint

Sfruttando la distribuzione a posteriori possiamo calcolare le probabilità associate a qualunque ipotesi: ad esempio
\begin{itemize}
 \item $Pr( \delta > 0 )$
<<results='markup'>>=
cat("> sum( samples[,'delta'] > 0 ) /",B,"\n")
@
\pause \vspace{-.3cm}
<<echo=FALSE,results='markup'>>=
sum( samples[,'delta'] > 0 )/B
@
\pause  \item $Pr( \delta > 2 )$
<<results='markup'>>=
cat("> sum( samples[,'delta'] > 2 ) /",B,"\n")
@
\pause \vspace{-.3cm}
<<echo=FALSE,results='markup'>>=
sum( samples[,'delta'] > 2 )/B
@
\pause  \item $Pr( 1 > \delta > 2 )$
<<results='markup'>>=
cat("> sum( samples[,'delta'] > 1 & ","\n")
cat("+  samples[,'delta'] < 2 ) /",B,"\n")

@
\pause \vspace{-.3cm}
<<echo=FALSE,results='markup'>>=
sum( samples[,'delta'] > 1 & samples[,'delta'] < 2 )/B
@

\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{.}
\begin{frame}[plain]
  \frametitle{}

\begin{flushright}
  \scalebox{.013}{\includegraphics{img/logo_psicostat.png}}
\end{flushright}


\vspace{1.5cm}
\begin{center}
\texttt{massimiliano.pastore@unipd.it}
\url{https://psicostat.dpss.psy.unipd.it/}
\end{center}

\vspace{1cm}
\begin{flushright}
  \scalebox{.25}{\includegraphics{img/loghi2017.png}}
\end{flushright}
\end{frame}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%
<<>>=
# KUtils::pulizia(paste(main,"knitr",sep=""), tieni = c(".Rnw",".Rmd"))
@
\section{FINO QUI}

%%%%%%%%%%%%%%%%%%%%%
\section{FINO QUI}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%



